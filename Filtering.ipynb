{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assigning 'bus' and 'train'\n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over the groups\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Check if at least one observation has 'RE_FM' == 'TRN_' and no observations have 'RE_FM' == 'BUS_'\n",
    "    if 'TRN_' in group['RE_FM'].values and 'BUS_' not in group['RE_FM'].values:\n",
    "        # Assign 'train' to the rows\n",
    "        bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'train'\n",
    "\n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over the groups\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Check if at least one observation has 'RE_FM' == 'TRN_' and no observations have 'RE_FM' == 'TRN_'\n",
    "    if 'BUS_' in group['RE_FM'].values and 'TRN_' not in group['RE_FM'].values:\n",
    "        # Assign 'train' to the rows\n",
    "        bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'bus'\n",
    "\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "\n",
    "# Define disrupting values\n",
    "disrupting_values = ['WALK', 'AIR_', 'CARD', 'CAPR', 'UKNW', 'EBKE', 'EXRC', 'FERY', 'MBSR', 'OTHR', 'SCOT', 'NMOW']\n",
    "\n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over the groups\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Check if the sequence 'BUS_' followed by 'TRN_' is present in the group\n",
    "    if 'BUS_' in group['RE_FM'].values and 'TRN_' in group['RE_FM'].values:\n",
    "        # Find the indices of 'BUS_' and 'TRN_' observations\n",
    "        bus_indices = group.index[group['RE_FM'] == 'BUS_']\n",
    "        trn_indices = group.index[group['RE_FM'] == 'TRN_']\n",
    "        \n",
    "        # Iterate over each 'BUS_' index\n",
    "        for bus_index in bus_indices:\n",
    "            # Find the nearest 'TRN_' index after 'BUS_'\n",
    "            trn_after_bus = next((idx for idx in trn_indices if idx > bus_index), None)\n",
    "            \n",
    "            # Check if there are no disrupting values between 'BUS_' and 'TRN_'\n",
    "            if trn_after_bus is not None and not any(value in group.loc[bus_index:trn_after_bus, 'RE_FM'].values for value in disrupting_values):\n",
    "                # Assign 'bus_train' to the entire group\n",
    "                bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'bus_train'\n",
    "                break  # Move to the next group\n",
    "         # Iterate over each 'TRN_' index\n",
    "        for trn_index in trn_indices:\n",
    "            # Find the nearest 'BUS_' index after 'TRN_'\n",
    "            bus_after_trn = next((idx for idx in bus_indices if idx > trn_index), None)\n",
    "            \n",
    "            # Check if there are no disrupting values between 'TRN_' and 'BUS_'\n",
    "            if bus_after_trn is not None and not any(value in group.loc[trn_index:bus_after_trn, 'RE_FM'].values for value in disrupting_values):\n",
    "                # Assign 'bus_train' to the entire group\n",
    "                bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'bus_train'\n",
    "                break  # Move to the next group\n",
    "\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "\n",
    "#### Assigning 'train_train' \n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over the groups\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Check if 'bus_train' has already been assigned to the group\n",
    "    if 'bus_train' not in group['DR_BYTES_TYP'].values:\n",
    "        # Check if there are at least two consecutive occurrences of 'TRN_'\n",
    "        if 'TRN_' in group['RE_FM'].values and any(group['RE_FM'].iloc[i] == 'TRN_' and group['RE_FM'].iloc[i + 1] == 'TRN_' for i in range(len(group) - 1)):\n",
    "            # If the conditions are met, assign 'train_train' to the entire group\n",
    "            bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'train_train'\n",
    "\n",
    "### Assigning 'bus_bus'\n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over the groups\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Check if 'bus_train' has already been assigned to the group\n",
    "    if 'bus_train' not in group['DR_BYTES_TYP'].values:\n",
    "        # Check if there are at least two consecutive occurrences of 'BUS_'\n",
    "        if 'BUS_' in group['RE_FM'].values and any(group['RE_FM'].iloc[i] == 'BUS_' and group['RE_FM'].iloc[i + 1] == 'BUS_' for i in range(len(group) - 1)):\n",
    "            # If the conditions are met, assign 'bus_bus' to the entire group\n",
    "            bus_train_no_walk.loc[group.index, 'DR_BYTES_TYP'] = 'bus_bus'\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "bus_train_no_walk\n",
    "# Define the file path\n",
    "file_path = r'T:\\Traffic\\Shared\\Illia\\Helsingborg Kollbyten\\Uttag - ändra inget här\\bus_train_no_walk_check.xlsx'\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "bus_train_no_walk.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved successfully as an Excel file.\")\n",
    "## Counting transfers\n",
    "#### Assigning no transfers\n",
    "\n",
    "# Assign 'Inga byten' to 'N_BYTES_PT' where 'DR_BYTES_TYP' is 'bus' or 'train'\n",
    "bus_train_no_walk.loc[bus_train_no_walk['DR_BYTES_TYP'].isin(['bus', 'train']), 'N_BYTES_PT'] = 'Inga byten'\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('N_BYTES_PT')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "# Define the disrupting values\n",
    "disrupting_values = ['WALK', 'AIR_', 'CARD', 'CAPR', 'UKNW', 'EBKE', 'EXRC', 'FERY', 'MBSR', 'OTHR', 'SCOT', 'NMOW']\n",
    "\n",
    "# Function to calculate the longest sequence of 'BUS_' and 'TRN_' without disruption\n",
    "def calculate_longest_sequence(group):\n",
    "    # Construct the regular expression pattern\n",
    "    pattern = '|'.join(disrupting_values)\n",
    "\n",
    "    # Extract sequences of 'BUS_' and 'TRN_' from 'RE_FM'\n",
    "    sequences = re.split(pattern, ''.join(group['RE_FM']))\n",
    "\n",
    "    # Remove empty strings from the sequences\n",
    "    sequences = [seq for seq in sequences if seq]\n",
    "\n",
    "    # Find the longest sequence of 'BUS_' and 'TRN_'\n",
    "    max_length = 0\n",
    "    for seq in sequences:\n",
    "        bus_trn_count = seq.count('BUS_') + seq.count('TRN_')\n",
    "        max_length = max(max_length, bus_trn_count)\n",
    "\n",
    "    return max_length - 1\n",
    "\n",
    "# Group the data by 'DR_ID'\n",
    "grouped_by_dr_id = bus_train_no_walk.groupby('DR_ID')\n",
    "\n",
    "# Iterate over groups of DR_ID\n",
    "for _, group in grouped_by_dr_id:\n",
    "    # Skip groups where 'N_BYTES_PT' is already assigned\n",
    "    if not group['N_BYTES_PT'].isnull().all() and 'Inga byten' in group['N_BYTES_PT'].tolist():\n",
    "        continue\n",
    "    \n",
    "    # Calculate the longest sequence without disruption\n",
    "    num_observations = calculate_longest_sequence(group)\n",
    "    \n",
    "    # Assign the value to the entire group in the column 'N_BYTES_PT'\n",
    "    bus_train_no_walk.loc[group.index, 'N_BYTES_PT'] = num_observations\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('N_BYTES_PT')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "bus_train_no_walk.dtypes\n",
    "# Ensure 'N_BYTES_PT' is treated as string type\n",
    "bus_train_no_walk['N_BYTES_PT'] = bus_train_no_walk['N_BYTES_PT'].astype(str)\n",
    "\n",
    "# Replace '-1' and '0' with an empty string in the 'N_BYTES_PT' column\n",
    "bus_train_no_walk['N_BYTES_PT'].replace({'-1': '', '0': ''}, inplace=True)\n",
    "\n",
    "# Group the data by 'DR_BYTES_TYP' and count the unique 'DR_ID' within each group\n",
    "unique_dr_id_counts = bus_train_no_walk.groupby('N_BYTES_PT')['DR_ID'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique DR_ID assigned to different categories by 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_id_counts)\n",
    "## Reporting\n",
    "# Read the Excel file\n",
    "assigned_bus_train = pd.read_excel(r'T:\\***bus_train_no_walk_report.xlsx')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "assigned_bus_train.head()\n",
    "# Count unique DR_ID values if 'DR_BYTES_TYP' is not null\n",
    "unique_dr_ids = assigned_bus_train[~assigned_bus_train['DR_BYTES_TYP'].isnull()].groupby('N_BYTES_PT')['DR_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of unique DR_ID assigned categories:\", unique_dr_ids)\n",
    "\n",
    "# Group by 'DR_BYTES_TYP' and count unique DR_IDs for each category where 'N_BYTES_PT' is 'Inga byten'\n",
    "unique_dr_ids = assigned_bus_train[assigned_bus_train['N_BYTES_PT'] == 'Inga byten'].groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of unique DR_IDs with 'N_BYTES_PT' = 'Inga byten' by category in 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_ids)\n",
    "\n",
    "# Group by 'DR_BYTES_TYP' and count unique DR_IDs for each category where 'N_BYTES_PT' is 'Inga byten'\n",
    "unique_dr_ids = assigned_bus_train[assigned_bus_train['N_BYTES_PT'] == '1'].groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of unique DR_IDs with 'N_BYTES_PT' = '1' by category in 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_ids)\n",
    "\n",
    "# Group by 'DR_BYTES_TYP' and count unique DR_IDs for each category where 'N_BYTES_PT' is 'Inga byten'\n",
    "unique_dr_ids = assigned_bus_train[assigned_bus_train['N_BYTES_PT'] == '2'].groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of unique DR_IDs with 'N_BYTES_PT' = '2' by category in 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_ids)\n",
    "\n",
    "# Define the categories to filter out\n",
    "excluded_categories = ['Inga byten', '1', '2']\n",
    "\n",
    "# Filter the DataFrame to exclude the specified categories in 'N_BYTES_PT'\n",
    "filtered_df = assigned_bus_train[~assigned_bus_train['N_BYTES_PT'].isin(excluded_categories)]\n",
    "\n",
    "# Group by 'DR_BYTES_TYP' and count unique DR_IDs for each category\n",
    "unique_dr_ids = filtered_df.groupby('DR_BYTES_TYP')['DR_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of unique DR_IDs with 'N_BYTES_PT' not in ['Inga byten', '1', '2'] by category in 'DR_BYTES_TYP':\")\n",
    "print(unique_dr_ids)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
